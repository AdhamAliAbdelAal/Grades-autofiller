{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "1f4efafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from crop_image import *\n",
    "import imutils\n",
    "import commonfunctions\n",
    "from commonfunctions import *\n",
    "from imutils import contours as imcnts\n",
    "import skimage.io as io\n",
    "from skimage.exposure import histogram\n",
    "from bubble_sheet_answer import *\n",
    "from paper_extraction import *\n",
    "from crop_image import *\n",
    "import pickle\n",
    "import statistics\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "08d3c18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_hog_features(img):\n",
    "    \n",
    "    win_size = (28, 28)\n",
    "    cell_size = (4, 4)\n",
    "    block_size_in_cells = (2, 2)\n",
    "    \n",
    "    block_size = (block_size_in_cells[1] * cell_size[1], block_size_in_cells[0] * cell_size[0])\n",
    "    block_stride = (cell_size[1], cell_size[0])\n",
    "    nbins = 9  # Number of orientation bins\n",
    "    hog = cv2.HOGDescriptor(win_size, block_size, block_stride, cell_size, nbins)\n",
    "    h = hog.compute(img)\n",
    "    h = h.flatten()\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "9bf69a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_models():\n",
    "    loaded_svc = pickle.load(open('./Train/SVC.sav', 'rb'))\n",
    "    loaded_knn = pickle.load(open('./Train/KNN.sav', 'rb'))\n",
    "    loaded_rf = pickle.load(open('./Train/RF.sav', 'rb'))\n",
    "    loaded_lr = pickle.load(open('./Train/LR.sav', 'rb'))\n",
    "\n",
    "    return loaded_svc, loaded_knn, loaded_rf, loaded_lr\n",
    "\n",
    "\n",
    "#####################################################################\n",
    "loaded_svc, loaded_knn, loaded_rf, loaded_lr = load_models()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "96f19153",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_the_paper_from_image_ID(image):\n",
    "        paper = None\n",
    "        contours, _ = cv2.findContours(image,cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "        if (len(contours) > 0):\n",
    "            contours = sorted(contours, key=cv2.contourArea, reverse=True)\n",
    "            paper_contour = None\n",
    "            paper = image\n",
    "            for cnt in contours:\n",
    "                peri = cv2.arcLength(cnt, True)\n",
    "                ratio = 0.01\n",
    "                approx = cv2.approxPolyDP(cnt, ratio*peri, True)\n",
    "                if (len(approx) == 4 and cv2.contourArea(cnt)>0.2*image.shape[0]*image.shape[1]):\n",
    "                    paper_contour = approx\n",
    "                    paper = four_point_transform(image, paper_contour.reshape(4, 2))\n",
    "                else:\n",
    "                    break\n",
    "        [intX, intY, intW, intH] = cv2.boundingRect(idBoxContour)\n",
    "        idBoxImage = paper[intY+5:intY+intH-5, intX+5:intX+intW-5]\n",
    "        return paper\n",
    "\n",
    "def classifier_algorithm (myc, median_width, image, loaded_svc, loaded_knn, loaded_rf, loaded_lr):\n",
    "    ID_weights = [1,7,1,1,2,1,1,22,4,1]\n",
    "    strFinalString=\"\"\n",
    "    classifiers_respond = np.zeros(10)\n",
    "    \n",
    "    [intX, intY, intW, intH] = cv2.boundingRect(myc)\n",
    "    imgROI = image[intY:intY+intH, intX:intX+intW]\n",
    "    \n",
    "    if(cv2.contourArea(myc)):\n",
    "        imgROIResized = cv2.resize(imgROI, (28, 28), cv2.INTER_NEAREST)\n",
    "\n",
    "        finalResized = imgROIResized.reshape((-1,1))\n",
    "        \n",
    "        \n",
    "        #EXTRACTING FEATURES\n",
    "        show_images([imgROIResized], ['Image in Classifier'])\n",
    "        hog_of_img = np.asarray(extract_hog_features(imgROIResized))\n",
    "        hog_of_img = hog_of_img.reshape(1,-1)\n",
    "        knn_value = loaded_knn.predict(hog_of_img)\n",
    "        rf_value = loaded_rf.predict(hog_of_img)\n",
    "        svc_value = loaded_svc.predict(hog_of_img)\n",
    "        lr_value = loaded_lr.predict(hog_of_img)\n",
    "        classifiers_respond[int(knn_value)] = classifiers_respond[int(knn_value)] + ID_weights[int(knn_value)]\n",
    "        classifiers_respond[int(rf_value)] = classifiers_respond[int(rf_value)] + ID_weights[int(rf_value)]\n",
    "        classifiers_respond[int(svc_value)] = classifiers_respond[int(svc_value)] + ID_weights[int(svc_value)]\n",
    "        classifiers_respond[int(lr_value)] = classifiers_respond[int(lr_value)] + ID_weights[int(lr_value)]\n",
    "        final_value = str(np.argmax(classifiers_respond))\n",
    "        \n",
    "        tmpString = str(int(final_value))\n",
    "        strFinalString = strFinalString + tmpString\n",
    "    return strFinalString\n",
    "\n",
    "def detect_id(img, loaded_svc, loaded_knn, loaded_rf, loaded_lr):\n",
    "    #PRE-PROCESSING\n",
    "    bf = cv2.bilateralFilter(img, 50, 100, 100) #to remove noise\n",
    "    imgGray = cv2.cvtColor(bf, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    th = cv2.adaptiveThreshold(imgGray, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY,7 , 3)\n",
    "#     th= cv2.adaptiveThreshold(imgGray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,  cv2.THRESH_BINARY, 51, 12)\n",
    "    plt.imshow(th,cmap='gray')\n",
    "    th=np.invert(th)\n",
    "    #plt.imshow(th,cmap='gray')\n",
    "    imgDigit = th\n",
    "\n",
    "\n",
    "    strFinalString = \"\"\n",
    "    plt.imshow(imgDigit,cmap='gray')\n",
    "    imgDigit = extract_the_paper_from_image_ID(imgDigit)\n",
    "    imgDigit = cv2.dilate(imgDigit, np.ones((2,2)),iterations = 1)\n",
    "    show_images([imgDigit], ['Removed Outer Contour'])\n",
    "    \n",
    "    width_sum=[]\n",
    "    cntr, h = cv2.findContours(imgDigit, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    print(len(cntr))\n",
    "    for cnt in cntr:\n",
    "        [intX, intY, intW, intH] = cv2.boundingRect(cnt)\n",
    "        show_images([imgDigit[intY:intY+intH, intX:intX+intW]],['Contours'])\n",
    "        print(intW)\n",
    "        if(intW>5):\n",
    "            width_sum = np.append(width_sum , [intW])\n",
    "\n",
    "    median_width = statistics.median(width_sum)\n",
    "    cntr,_=imcnts.sort_contours(cntr,method='left-to-right')\n",
    "    for myc in cntr:\n",
    "        [intX, intY, intW, intH] = cv2.boundingRect(myc)\n",
    "        if (intH>15 and intW*intH<0.5*imgDigit.shape[0]*imgDigit.shape[1]):\n",
    "            strFinalString = strFinalString + classifier_algorithm(myc, median_width,imgDigit, loaded_svc, loaded_knn, loaded_rf, loaded_lr)\n",
    "    return strFinalString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "6e2f1a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_the_paper_from_image(image):\n",
    "        gray_scale = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        adaptively_thresholded = cv2.adaptiveThreshold(gray_scale,255,cv2.ADAPTIVE_THRESH_MEAN_C,cv2.THRESH_BINARY,11,2)\n",
    "        plt.imshow(adaptively_thresholded,cmap='gray')\n",
    "        contours, _ = cv2.findContours(adaptively_thresholded,\n",
    "                                       cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "        if (len(contours) > 0):\n",
    "            contours = sorted(contours, key=cv2.contourArea, reverse=True)\n",
    "            paper_contour = None\n",
    "            paper = image\n",
    "            for cnt in contours:\n",
    "                peri = cv2.arcLength(cnt, True)\n",
    "                ratio = 0.01\n",
    "                approx = cv2.approxPolyDP(cnt, ratio*peri, True)\n",
    "                print(len(approx),cv2.contourArea(cnt), image.shape[0]*image.shape[1])\n",
    "                if (len(approx) == 4 and cv2.contourArea(cnt)>0.2*image.shape[0]*image.shape[1]):\n",
    "                    paper_contour = approx\n",
    "                    paper = four_point_transform(image, paper_contour.reshape(4, 2))\n",
    "                else:\n",
    "                    break\n",
    "        return idBoxImage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "42410f68",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Image data of dtype object cannot be converted to float",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [313]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m image\u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid_test/test_id3.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m) \n\u001b[1;32m----> 2\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcmap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgray\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m paper\u001b[38;5;241m=\u001b[39mextract_the_paper_from_image(image)\n\u001b[0;32m      4\u001b[0m temp\u001b[38;5;241m=\u001b[39mpaper\u001b[38;5;241m.\u001b[39mcopy()\n",
      "File \u001b[1;32mE:\\anaconda\\lib\\site-packages\\matplotlib\\_api\\deprecation.py:456\u001b[0m, in \u001b[0;36mmake_keyword_only.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    450\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m name_idx:\n\u001b[0;32m    451\u001b[0m     warn_deprecated(\n\u001b[0;32m    452\u001b[0m         since, message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPassing the \u001b[39m\u001b[38;5;132;01m%(name)s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%(obj_type)s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    453\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpositionally is deprecated since Matplotlib \u001b[39m\u001b[38;5;132;01m%(since)s\u001b[39;00m\u001b[38;5;124m; the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    454\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter will become keyword-only \u001b[39m\u001b[38;5;132;01m%(removal)s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    455\u001b[0m         name\u001b[38;5;241m=\u001b[39mname, obj_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m()\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mE:\\anaconda\\lib\\site-packages\\matplotlib\\pyplot.py:2640\u001b[0m, in \u001b[0;36mimshow\u001b[1;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, data, **kwargs)\u001b[0m\n\u001b[0;32m   2634\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[38;5;241m.\u001b[39mimshow)\n\u001b[0;32m   2635\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mimshow\u001b[39m(\n\u001b[0;32m   2636\u001b[0m         X, cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, aspect\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, interpolation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   2637\u001b[0m         alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, vmin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, vmax\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, origin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, extent\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m,\n\u001b[0;32m   2638\u001b[0m         interpolation_stage\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, filternorm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, filterrad\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4.0\u001b[39m,\n\u001b[0;32m   2639\u001b[0m         resample\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, url\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m-> 2640\u001b[0m     __ret \u001b[38;5;241m=\u001b[39m gca()\u001b[38;5;241m.\u001b[39mimshow(\n\u001b[0;32m   2641\u001b[0m         X, cmap\u001b[38;5;241m=\u001b[39mcmap, norm\u001b[38;5;241m=\u001b[39mnorm, aspect\u001b[38;5;241m=\u001b[39maspect,\n\u001b[0;32m   2642\u001b[0m         interpolation\u001b[38;5;241m=\u001b[39minterpolation, alpha\u001b[38;5;241m=\u001b[39malpha, vmin\u001b[38;5;241m=\u001b[39mvmin,\n\u001b[0;32m   2643\u001b[0m         vmax\u001b[38;5;241m=\u001b[39mvmax, origin\u001b[38;5;241m=\u001b[39morigin, extent\u001b[38;5;241m=\u001b[39mextent,\n\u001b[0;32m   2644\u001b[0m         interpolation_stage\u001b[38;5;241m=\u001b[39minterpolation_stage,\n\u001b[0;32m   2645\u001b[0m         filternorm\u001b[38;5;241m=\u001b[39mfilternorm, filterrad\u001b[38;5;241m=\u001b[39mfilterrad, resample\u001b[38;5;241m=\u001b[39mresample,\n\u001b[0;32m   2646\u001b[0m         url\u001b[38;5;241m=\u001b[39murl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m: data} \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {}),\n\u001b[0;32m   2647\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   2648\u001b[0m     sci(__ret)\n\u001b[0;32m   2649\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m __ret\n",
      "File \u001b[1;32mE:\\anaconda\\lib\\site-packages\\matplotlib\\_api\\deprecation.py:456\u001b[0m, in \u001b[0;36mmake_keyword_only.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    450\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m name_idx:\n\u001b[0;32m    451\u001b[0m     warn_deprecated(\n\u001b[0;32m    452\u001b[0m         since, message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPassing the \u001b[39m\u001b[38;5;132;01m%(name)s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%(obj_type)s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    453\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpositionally is deprecated since Matplotlib \u001b[39m\u001b[38;5;132;01m%(since)s\u001b[39;00m\u001b[38;5;124m; the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    454\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter will become keyword-only \u001b[39m\u001b[38;5;132;01m%(removal)s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    455\u001b[0m         name\u001b[38;5;241m=\u001b[39mname, obj_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m()\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mE:\\anaconda\\lib\\site-packages\\matplotlib\\__init__.py:1412\u001b[0m, in \u001b[0;36m_preprocess_data.<locals>.inner\u001b[1;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1409\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m   1410\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(ax, \u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m   1411\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1412\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(ax, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mmap\u001b[39m(sanitize_sequence, args), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1414\u001b[0m     bound \u001b[38;5;241m=\u001b[39m new_sig\u001b[38;5;241m.\u001b[39mbind(ax, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1415\u001b[0m     auto_label \u001b[38;5;241m=\u001b[39m (bound\u001b[38;5;241m.\u001b[39marguments\u001b[38;5;241m.\u001b[39mget(label_namer)\n\u001b[0;32m   1416\u001b[0m                   \u001b[38;5;129;01mor\u001b[39;00m bound\u001b[38;5;241m.\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mget(label_namer))\n",
      "File \u001b[1;32mE:\\anaconda\\lib\\site-packages\\matplotlib\\axes\\_axes.py:5488\u001b[0m, in \u001b[0;36mAxes.imshow\u001b[1;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, **kwargs)\u001b[0m\n\u001b[0;32m   5481\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_aspect(aspect)\n\u001b[0;32m   5482\u001b[0m im \u001b[38;5;241m=\u001b[39m mimage\u001b[38;5;241m.\u001b[39mAxesImage(\u001b[38;5;28mself\u001b[39m, cmap, norm, interpolation,\n\u001b[0;32m   5483\u001b[0m                       origin, extent, filternorm\u001b[38;5;241m=\u001b[39mfilternorm,\n\u001b[0;32m   5484\u001b[0m                       filterrad\u001b[38;5;241m=\u001b[39mfilterrad, resample\u001b[38;5;241m=\u001b[39mresample,\n\u001b[0;32m   5485\u001b[0m                       interpolation_stage\u001b[38;5;241m=\u001b[39minterpolation_stage,\n\u001b[0;32m   5486\u001b[0m                       \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m-> 5488\u001b[0m \u001b[43mim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5489\u001b[0m im\u001b[38;5;241m.\u001b[39mset_alpha(alpha)\n\u001b[0;32m   5490\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m im\u001b[38;5;241m.\u001b[39mget_clip_path() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   5491\u001b[0m     \u001b[38;5;66;03m# image does not already have clipping set, clip to axes patch\u001b[39;00m\n",
      "File \u001b[1;32mE:\\anaconda\\lib\\site-packages\\matplotlib\\image.py:706\u001b[0m, in \u001b[0;36m_ImageBase.set_data\u001b[1;34m(self, A)\u001b[0m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_A \u001b[38;5;241m=\u001b[39m cbook\u001b[38;5;241m.\u001b[39msafe_masked_invalid(A, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    704\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_A\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39muint8 \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    705\u001b[0m         \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39mcan_cast(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_A\u001b[38;5;241m.\u001b[39mdtype, \u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msame_kind\u001b[39m\u001b[38;5;124m\"\u001b[39m)):\n\u001b[1;32m--> 706\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImage data of dtype \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m cannot be converted to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    707\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_A\u001b[38;5;241m.\u001b[39mdtype))\n\u001b[0;32m    709\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_A\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_A\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    710\u001b[0m     \u001b[38;5;66;03m# If just one dimension assume scalar and apply colormap\u001b[39;00m\n\u001b[0;32m    711\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_A \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_A[:, :, \u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mTypeError\u001b[0m: Image data of dtype object cannot be converted to float"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image= cv2.imread('id_test/test_id3.jpg') \n",
    "plt.imshow(image,cmap='gray')\n",
    "paper=extract_the_paper_from_image(image)\n",
    "temp=paper.copy()\n",
    "#paper=extract_the_paper_from_image(paper)\n",
    "bubble_size=(5,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02758e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the gray scale paper \n",
    "gray_scale_paper = cv2.cvtColor(paper,cv2.COLOR_BGR2GRAY)\n",
    "plt.imshow(gray_scale_paper,cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84d83c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fedff7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d42985d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get binary paper\n",
    "thresholded=cv2.adaptiveThreshold(gray_scale_paper, 255, cv2.ADAPTIVE_THRESH_MEAN_C,cv2.THRESH_BINARY_INV, 73, 5)\n",
    "plt.figure()\n",
    "plt.imshow(thresholded,cmap='gray')\n",
    "# # Make Morphological Operation (Opening To Spilit Bubbles From Each Others)\n",
    "# thresholded=cv2.morphologyEx(thresholded, cv2.MORPH_OPEN, np.ones((2,2)))\n",
    "# plt.figure()\n",
    "# plt.imshow(thresholded,cmap='gray')\n",
    "# thresholded = cv2.dilate(thresholded,np.ones((2,2)),iterations = 1)\n",
    "# plt.figure()\n",
    "# plt.imshow(thresholded,cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3587d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract id box from image\n",
    "cntr, h = cv2.findContours(thresholded, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "cnt = sorted(cntr, key=cv2.contourArea, reverse=True)\n",
    "for c in cnt:\n",
    "    peri = cv2.arcLength(c, True)\n",
    "    ratio = 0.01\n",
    "    approx = cv2.approxPolyDP(c, ratio*peri, True)\n",
    "    if (len(approx) == 4):\n",
    "        print('here')\n",
    "        idBoxContour= c\n",
    "        [intX, intY, intW, intH] = cv2.boundingRect(idBoxContour)\n",
    "        idBoxImage = paper[intY:intY+intH, intX:intX+intW]\n",
    "        thresholded[intY:intY+intH, intX:intX+intW] = 0\n",
    "        break\n",
    "show_images([idBoxImage], ['ID BOX'])\n",
    "id = detect_id(idBoxImage, loaded_svc, loaded_knn, loaded_rf, loaded_lr)\n",
    "print('id = ',id)\n",
    "plt.figure()\n",
    "plt.imshow(thresholded, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010470fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eroded=cv2.dilate(thresholded,np.ones((2,2)),iterations=2)\n",
    "# plt.figure()\n",
    "# plt.imshow(thresholded,cmap='gray')\n",
    "# eroded = cv2.morphologyEx(thresholded, cv2.MORPH_OPEN, np.ones((3,3)))\n",
    "eroded=cv2.erode(thresholded,np.ones((3,3)),iterations=1)\n",
    "# plt.figure()\n",
    "# plt.imshow(eroded,cmap='gray')\n",
    "# eroded=cv2.dilate(eroded,np.ones((2,2)),iterations=5)\n",
    "plt.figure()\n",
    "plt.imshow(eroded,cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2c0ac6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be5f770",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d339f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get Average Area\n",
    "areas=[]\n",
    "# Get the external contours\n",
    "pap_cnts,_=cv2.findContours(thresholded, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "# Check if there are no contours\n",
    "if(len(pap_cnts)==0):\n",
    "    print(\"No external contours found\")\n",
    "\n",
    "# Get the bubbles contours\n",
    "pre_question_cnts=[]\n",
    "for cnt in pap_cnts:\n",
    "    (x,y,w,h)=cv2.boundingRect(cnt)\n",
    "    aspect_ratio=w/h\n",
    "    peri = cv2.arcLength(cnt, True)\n",
    "    ratio = 0.01\n",
    "    approx = cv2.approxPolyDP(cnt, ratio*peri, True)\n",
    "    if(aspect_ratio>=0.8 and aspect_ratio<=1.2 and len(approx)>=4 and cv2.contourArea(cnt)>30 and cv2.contourArea(cnt)>1.5*peri):\n",
    "        areas.append(cv2.contourArea(cnt))\n",
    "        pre_question_cnts.append(cnt)\n",
    "        print(len(approx))\n",
    "\n",
    "# Check if there are no contours\n",
    "if(len(pre_question_cnts)==0):\n",
    "    print(\"No bubbles contours found\")\n",
    "print(len(pre_question_cnts),len(pap_cnts))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06769b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp3333=paper.copy()\n",
    "cv2.drawContours(temp3333,pre_question_cnts,-1,(0,255,0), 5)\n",
    "plt.figure()\n",
    "plt.imshow(temp3333)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3a02ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(cnt_cont,sum_cont_area,sum_cont_area/cnt_cont)\n",
    "bubble_area=np.median(areas)\n",
    "print(bubble_area)\n",
    "#print(np.median(areas))\n",
    "#print(np.amin(areas))\n",
    "question_cnts_copy=[]\n",
    "for i,area  in enumerate(areas):\n",
    "    #print(i,area,abs(area-bubble_area))\n",
    "    if(abs(area-bubble_area)<=bubble_area*.3):\n",
    "        question_cnts_copy.append(pre_question_cnts[i])\n",
    "pre_question_cnts= question_cnts_copy      \n",
    "print(len(pre_question_cnts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae0208d",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp3333=paper.copy()\n",
    "cv2.drawContours(temp3333,pre_question_cnts,-1,(0,255,0), 5)\n",
    "plt.figure()\n",
    "plt.imshow(temp3333)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d6dc2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if(len(pre_question_cnts)):\n",
    "    # Sort the contours from top to bottom\n",
    "    question_cnts,_=imcnts.sort_contours(pre_question_cnts,method='top-to-bottom')\n",
    "\n",
    "    # Detect the number of choices and the number of columns\n",
    "    xs_set=np.array([])\n",
    "    (_,__,bubble_width,___)=cv2.boundingRect(pre_question_cnts[0])\n",
    "    for cnt in question_cnts:\n",
    "        (x,y,w,h)=cv2.boundingRect(cnt)\n",
    "        xs_set=np.append(xs_set,x)\n",
    "    xs_set=np.sort(xs_set)\n",
    "    number_of_bubbles=0\n",
    "    number_of_xs=len(xs_set)\n",
    "    number_of_columns=1\n",
    "    print(xs_set,bubble_width)\n",
    "    for i in range(1,number_of_xs):\n",
    "        #print(xs_set[i]-xs_set[i-1])\n",
    "        if(xs_set[i]-xs_set[i-1]>=0.5*bubble_width and xs_set[i]-xs_set[i-1]<=2*bubble_width):\n",
    "            number_of_bubbles+=1\n",
    "        elif(xs_set[i]-xs_set[i-1]>2.5*bubble_width):\n",
    "            number_of_columns+=1\n",
    "    number_of_bubbles+=number_of_columns\n",
    "    number_of_choices=number_of_bubbles//number_of_columns\n",
    "    print(number_of_columns,number_of_choices,number_of_bubbles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d8c0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors=[(255,0,0)\n",
    ",(0,255,0)\n",
    ",(0,0,255)\n",
    ",(255,0,0)\n",
    ",(0,255,0)\n",
    ",(0,0,255)\n",
    ",(0,255,0)\n",
    ",(255,0,0)\n",
    ",(255,255,192)\n",
    ",(225,255,128)\n",
    ",(128,0,0)\n",
    ",(128,128,0)\n",
    ",(0,128,0)\n",
    ",(128,0,128)\n",
    ",(0,128,128)\n",
    ",(0,0,128),\n",
    "       (255,215,0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b99d551",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_number_of_contours(cnts):\n",
    "    (_,prev_y,___,bubble_height)=cv2.boundingRect(cnts[0])\n",
    "    #print(\"height\",bubble_height)\n",
    "    for i,cnt in enumerate(cnts):\n",
    "        (x,y,w,h)=cv2.boundingRect(cnt)\n",
    "        #print(\"y\",y)\n",
    "        if(abs(y-prev_y)>0.3*bubble_height):\n",
    "            #print(\"abs\",abs(y-prev_y))\n",
    "            return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7a8eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_questions=len(pre_question_cnts)//number_of_choices\n",
    "cut_row=10000000\n",
    "is_cut=0\n",
    "if(len(pre_question_cnts)):\n",
    "    qs=0\n",
    "    # Get student answers\n",
    "    answers=[]\n",
    "    temp_number_of_columns=number_of_columns\n",
    "    # Iterate over each row\n",
    "    i=0\n",
    "    while (i<len(question_cnts)):\n",
    "        # detect number of contours in row\n",
    "        if(not is_cut):\n",
    "            is_cut=detect_number_of_contours(question_cnts[i:i+number_of_columns*number_of_choices])\n",
    "            if(is_cut):\n",
    "                temp_number_of_columns-=1\n",
    "            cut_row=i\n",
    "            print(\"its ok\",temp_number_of_columns,cut_row)\n",
    "            \n",
    "        number_of_conts=temp_number_of_columns*number_of_choices\n",
    "        print(\"conts\",number_of_conts)\n",
    "\n",
    "        # Get all bubbles of the current row which has (number_of_columns) questions\n",
    "        curr_row_cnts,_=imcnts.sort_contours(question_cnts[i:i+number_of_conts])\n",
    "        #print(curr_row_cnts)\n",
    "        \n",
    "        # Iterate over each question\n",
    "        for k in np.arange(0,len(curr_row_cnts),number_of_choices):\n",
    "\n",
    "            # Current Question answers\n",
    "            curr_ques_cnts=curr_row_cnts[k:k+number_of_choices]\n",
    "            color1=colors[qs%len(colors)]\n",
    "            qs=qs+1\n",
    "            cv2.drawContours(temp,curr_ques_cnts,-1,color1, 5)\n",
    "\n",
    "            mask_ones=[]\n",
    "            bubbles=[]\n",
    "            for j,c in enumerate(curr_ques_cnts):\n",
    "\n",
    "                # Get the maximum shaded bubble\n",
    "                mask = np.zeros(thresholded.shape, dtype=\"uint8\")\n",
    "                cv2.drawContours(mask, [c], -1, 255, -1)\n",
    "                mask_ones.append(cv2.countNonZero(mask))\n",
    "                mask= cv2.bitwise_and(eroded, mask)\n",
    "                total= cv2.countNonZero(mask)\n",
    "                bubbles.append(total)\n",
    "            mask_mean=np.mean(mask_ones)\n",
    "            bubbles=np.array(bubbles)/mask_mean\n",
    "            bubbled=np.argmax(bubbles)\n",
    "            total=np.amax(bubbles)\n",
    "            count_chosen=0\n",
    "            if(total>0.7):\n",
    "                count_chosen=((total-bubbles)<=0.3).sum()\n",
    "            else:\n",
    "                count_chosen=((total-bubbles)<=0.15).sum()\n",
    "            final_ans=(ord('X')-ord('A')) if(count_chosen!=1) else bubbled\n",
    "            answers.append(chr(final_ans+ord('A')))\n",
    "        print(\"PCCCCCCCCCCCCC\",i,temp_number_of_columns)\n",
    "        i+=(temp_number_of_columns*number_of_choices)\n",
    "    print(answers,len(answers))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ab2fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(temp)\n",
    "# paper=extract_the_paper_from_image(image)\n",
    "#paper=extract_the_paper_from_image(paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577ca784",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_rows=0\n",
    "x_sorted_conts,_=imcnts.sort_contours(question_cnts)\n",
    "(prev_x,_,bubble_width,__)=cv2.boundingRect(x_sorted_conts[0])\n",
    "for i,cnt in enumerate(x_sorted_conts):\n",
    "    (x,y,w,h)=cv2.boundingRect(cnt)\n",
    "    #print(\"y\",y)\n",
    "#     print(prev_x,x,bubble_width,i)\n",
    "    if(abs(prev_x-x)>=2.5*bubble_width):\n",
    "        number_of_rows=i\n",
    "        break\n",
    "    prev_x=x\n",
    "print(number_of_rows//number_of_choices)\n",
    "number_of_rows=number_of_rows//number_of_choices\n",
    "number_of_rows=number_of_questions if not number_of_rows else number_of_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6917d1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cut_row,cut_row//(number_of_choices*number_of_columns))\n",
    "cut_row=cut_row//(number_of_choices*number_of_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21bdc950",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_cnt=0\n",
    "final_answers=[0] * number_of_questions\n",
    "for i in range(0,number_of_rows):\n",
    "    for j in range(0,number_of_columns-int(i>=cut_row and cut_row!=number_of_rows-1)):\n",
    "        print(curr_cnt+1,j*number_of_rows+i+1,int(i>=cut_row and cut_row!=number_of_rows-1))\n",
    "        final_answers[j*number_of_rows+i]=answers[curr_cnt]\n",
    "        curr_cnt+=1\n",
    "print(final_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa8bf5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key,val in enumerate(final_answers):\n",
    "    print(key+1,val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7bffd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers[39]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3b9be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5543948",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
